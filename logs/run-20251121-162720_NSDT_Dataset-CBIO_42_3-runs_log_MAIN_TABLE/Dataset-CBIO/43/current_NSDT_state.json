{"messages": [{"role": "system", "content": "\nObjective: Write fully functional PyTorch code that fills the provided class skeleton ONLY, to create an effective differential-equation-like simulator for the specified environment. No placeholders, no extra files.\n\nNon-negotiable rules:\n- Do NOT change the class name, method names, argument order, or return types.\n- Fill ONLY the TODOs INSIDE the skeleton. You may define submodules and small private helper methods INSIDE the class, but must not add new public methods or change signatures.\n- Code must run with batch size = 1 (and any B>=1). Therefore:\n  * Do NOT use BatchNorm of any kind. If you need normalization, use LayerNorm.\n- Use only PyTorch standard library (torch, torch.nn, torch.nn.functional) and typing.Tuple.\n- All tensors are float32; assume inputs come as shape [B,1]. Concatenate on last dim.\n- Enforce numerical stability: clamp outputs to physiologically plausible ranges.\n- Treatment/control inputs MUST influence the dynamics as required by the environment.\n- Prefer monotone-increasing or monotone-decreasing effects when medically sensible (see env description).\n- Use LeakyReLU or ELU (avoid dead ReLU), Dropout in {0.1\u20130.3}, and avoid weight explosions.\n\nQuality bar:\n- Prefer a hybrid design: simple mechanistic prior + residual MLP correction.\n- If using gates, ensure positivity via Softplus.\n- No randomness, no training loops here, just the model class.\n\nSelf-checks inside forward:\n- Assert the concatenated input has last-dim size equal to the specified count.\n- Never return NaN/Inf; clamp derivatives.\n\nIndent code with tabs. Return the complete class code body."}, {"role": "user", "content": "\nYou will get a system description to code a differential equation simulator for.\n\nSystem Description:```\nDigital Twin Model for GIST Cancer (CBIO Longitudinal Dataset)\n\nGOAL:\nImplement a neural ODE-like differential model for Digital Twin generation. The model outputs 2 derivatives\nfor STATE variables, using 17 STATIC features (including genetics and treatment) and 2 CONTROL inputs.\n\nSTRUCTURAL CAUSAL MODEL (SCM) - CRITICAL:\nThe model architecture MUST respect the Causal Graph provided below. \nYou must ensure that the derivative calculations for the state variables (msi_score, tmb_nonsynonymous)\nincorporate their specific PARENTS defined in the SCM.\n\nKEY RELATIONSHIPS TO MODEL:\n- msi_score -> driven by msi_type, site_group, recurrence\n- tmb -> driven by tumor_purity\n- Treatment & Mutations (KIT, TP53) should modulate these dynamics globally via the latent state.\n\nINPUTS (order is FIXED - matches env.py):\n1. msi_score\n2. tmb_nonsynonymous\n3. age_at_diagnosis\n4. gender_encoded\n5. stage_encoded\n6. primary_site_group_encoded\n7. race_encoded\n8. recurrence_encoded\n9. tumor_purity\n10. msi_type_encoded\n11. sample_type_encoded\n12. tumor_size\n13. mitotic_rate\n14. sample_coverage\n15. treatment_encoded\n16. treatment_response_encoded\n17. has_kit_mutation\n18. has_tp53_mutation\n19. has_pdgfra_mutation\n20. treatment_duration_days (Control)\n21. recurrence_free_months (Control)\n\nOUTPUT:\n(d_msi_score__dt, d_tmb_nonsynonymous__dt)\n\n```\n\nSkeleton Code:\n```python\nclass StateDifferential(nn.Module):\n  def __init__(self):\n    super(StateDifferential, self).__init__()\n    # TODO: Fill in the code here\n    #\n    # SCM-INFORMED ARCHITECTURE for Digital Twin\n    #\n    # REQUIRED STRUCTURE:\n    # 1. Shared encoder (process all 21 inputs) -> Latent H\n    #\n    # 2. MSI Pathway (d_msi_score__dt):\n    #    - Must combine Latent H with specific SCM parents.\n    #\n    # 3. TMB Pathway (d_tmb_nonsynonymous__dt):\n    #    - Must combine Latent H with specific SCM parent.\n    #\n    # Use Small MLPs (e.g., 64->32) with Dropout(0.3).\n\n  def forward(self,\n              msi_score: torch.Tensor,\n              tmb_nonsynonymous: torch.Tensor,\n              age_at_diagnosis: torch.Tensor,\n              gender_encoded: torch.Tensor,\n              stage_encoded: torch.Tensor,\n              primary_site_group_encoded: torch.Tensor,\n              race_encoded: torch.Tensor,\n              recurrence_encoded: torch.Tensor,\n              tumor_purity: torch.Tensor,\n              msi_type_encoded: torch.Tensor,\n              sample_type_encoded: torch.Tensor,\n              tumor_size: torch.Tensor,\n              mitotic_rate: torch.Tensor,\n              sample_coverage: torch.Tensor,\n              treatment_encoded: torch.Tensor,\n              treatment_response_encoded: torch.Tensor,\n              has_kit_mutation: torch.Tensor,\n              has_tp53_mutation: torch.Tensor,\n              has_pdgfra_mutation: torch.Tensor,\n              treatment_duration_days: torch.Tensor,\n              recurrence_free_months: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    # TODO: Fill in the code here\n    # 1. Concatenate all inputs (21 dim)\n    # 2. Forward pass through shared encoder\n    # 3. Forward pass through SCM-specific heads\n    # 4. Clamp derivatives [-1, 1]\n    return (d_msi_score__dt, d_tmb_nonsynonymous__dt)\n```", "function_call": {"name": "complete_StateDifferential_code"}}], "simulator_code_dict": {}, "steps": [], "step": null, "meta_messages": [], "message_hash": "a1fb33070f6f8f851a389791904e48519bfb69fe39f1f99289c97ca54c7b2446"}